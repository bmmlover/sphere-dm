{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 5. Линейные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import random as pr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as pl\n",
    "import sklearn.cross_validation as cv\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "# Plotting config\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зачитываем результат 4 домашки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load(\"out_4.dat.npz\")\n",
    "users = data[\"users\"]\n",
    "X_dataset = data[\"data\"].reshape(1,)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6898, 164790)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зачитываем категории пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAINING_SET_URL = \"twitter_train.txt\"\n",
    "EXAMPLE_SET_URL = \"twitter_example.txt\"\n",
    "df_users_train = pd.read_csv(TRAINING_SET_URL, sep=\",\", header=0)\n",
    "df_users_ex = pd.read_csv(EXAMPLE_SET_URL, sep=\",\", header=0)\n",
    "df_users_ex['cat'] = None\n",
    "df_users = pd.concat([df_users_train, df_users_ex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель строим для пользователей из twitter_train, нужно выбрать этих пользователей из матрицы из 4 ДЗ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO check this code\n",
    "train_users = df_users_train[\"uid\"].values\n",
    "ix = np.in1d(users, train_users).reshape(users.shape) #можно np.in1d(users, train_users)\n",
    "X = X_dataset[np.where(ix)] #можно X_dataset[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(X_dataset[np.where(ix)].toarray(), X_dataset[ix].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 164790)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dataset[np.where(ix)].toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 164790)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dataset[ix].toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(np.in1d(users, train_users), np.in1d(users, train_users).reshape(users.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6898,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.in1d(users, train_users).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6898,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.in1d(users, train_users).reshape(users.shape).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формируем целевую переменную: Делаем join списка пользователей из ДЗ4 с обучающей выборкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting training set: (5000x164790) feature matrix, 5000 target vector\n"
     ]
    }
   ],
   "source": [
    "Y = df_users_train['cat'].values\n",
    "print \"Resulting training set: (%dx%d) feature matrix, %d target vector\" % (X.shape[0], X.shape[1], Y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы исследовать, как ведут себя признаки, построим распределение количества ненулевых признаков у пользователей, чтобы убедиться, что он удовлетворяет закону Ципфа. Для этого построим гистограмму в логарифмических осях. [Подсказка](http://anokhin.github.io/img/sf1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEHCAYAAACncpHfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nijIBSFJFmQAkqaJMAJJUUf8fUZ/7yS/+eCgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1119f3190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_log_hist(x):\n",
    "    \"\"\"Draw tokens histogram in log scales\"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    features_counts = (X.toarray()!=0).sum(axis = 0) + 1\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.scatter(xrange(1, x.shape[1]+1), sorted(features_counts, reverse=True))\n",
    "    return features_counts\n",
    "\n",
    "features_counts = draw_log_hist(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем отбор признаков. В самом простом случае просто удаляем признаки, имеющие ненулевое значение у менее, чем 100 пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = X.tocsc()[:, features_counts > 260].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант задания генерируется на основании вашего ника в техносфере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My homework 5 algorithm is: Logistic regression with L2 regularization optimized by Newton method\n"
     ]
    }
   ],
   "source": [
    "USER_NAME = \"m.belyalova\"\n",
    "OPTIMIZATION_ALGORITHMS = [\"stochastic gradient descent\", \"Newton method\"]\n",
    "REGULARIZATIONS = [\"L1\", \"L2\"]\n",
    "\n",
    "print \"My homework 5 algorithm is: Logistic regression with %s regularization optimized by %s\" % (\n",
    "    REGULARIZATIONS[hash(USER_NAME) % 2],\n",
    "    OPTIMIZATION_ALGORITHMS[hash(USER_NAME[::-1]) % 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем выбранный алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "from __future__ import division\n",
    "\n",
    "class LogisticRegression():\n",
    "    def __init__(self, max_iter=100, C=1000, step=1):\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.step = step\n",
    "    \n",
    "    def mnk(self, x, y, w=None):\n",
    "        if w == None:\n",
    "            w = np.zeros(x.shape[1])\n",
    "        inverted_hessian = inv(np.dot(x.T, x) + np.eye(x.shape[1]) * 2 * self.C)\n",
    "        grad_vector_with_l2 = np.dot(x.T, y) - 2 * self.C * w\n",
    "        return np.dot(inverted_hessian, grad_vector_with_l2)\n",
    "        #return np.dot(np.dot(inv(np.dot(X.T, X)), X.T), y)\n",
    "\n",
    "    def sigma(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def Newton_IRLS(self, X, Y):\n",
    "        #w = np.dot(inv(np.dot(self.X.T, self.X)), np.dot(self.X.T, self.Y))   \n",
    "        w = self.mnk(X, Y)\n",
    "        self.iters.append(w)\n",
    "        #pred_sigmas = np.zeros(self.X.shape[0])\n",
    "        for t in range(0, self.max_iter):\n",
    "            z = np.dot(X, w)\n",
    "            zy = np.multiply(z, Y)          \n",
    "            sigmas = self.sigma(zy)\n",
    "            weights = np.sqrt((1 - sigmas) * sigmas)\n",
    "    \n",
    "            X_weighted = np.dot(np.diag(weights), X)\n",
    "            y_weighted = np.multiply(Y, np.sqrt((1 - sigmas) / sigmas))\n",
    "            \n",
    "            #w_iter = np.dot(inv(np.dot(X_weighted.T, X_weighted)), np.dot(X_weighted.T, y_weighted) - self.C)\n",
    "            #w = w + step_t * w_iter\n",
    "            old_w = w\n",
    "            w = w + self.step * self.mnk(X_weighted, y_weighted, w)\n",
    "            if np.isnan(w[0]):\n",
    "                print 'Iteration method with such parameters doesn\\'t converge :('\n",
    "                return old_w\n",
    "            \n",
    "            self.iters.append(w)\n",
    "            \n",
    "            #if np.linalg.norm(sigmas - pred_sigmas) < self.eps:\n",
    "                #break\n",
    "            #pred_sigmas = sigmas\n",
    "        return w\n",
    "    \n",
    "    def fit(self, X, Y=None):\n",
    "        classes = np.unique(Y).tolist()\n",
    "        if len(classes) != 2:\n",
    "            raise ValueError('This classifier handles only two-class classification :(')\n",
    "        if classes != [-1, 1]:\n",
    "            Y = numpy.where(np.copy(Y) == classes[0], -1, np.copy(Y))\n",
    "            Y = numpy.where(np.copy(Y) == classes[1], 1, np.copy(Y))\n",
    "        X = np.hstack((X, np.ones(X.shape[0])[:,np.newaxis]))\n",
    "        self.iters = []\n",
    "        #self.X = X\n",
    "        #self.Y = Y\n",
    "        self.w = self.Newton_IRLS(X, Y)\n",
    "        print 'Classifier was fitted :)'\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        x = np.hstack((x, np.ones(x.shape[0])[:,np.newaxis]))\n",
    "        proba = 1 - 1 / (1 + np.exp(-x.dot(self.w[:,np.newaxis])))\n",
    "        proba = np.hstack((proba, 1/(1 + np.exp(-x.dot(self.w)))[:,np.newaxis]))\n",
    "        print 'Data was predicted :)'\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем метрику качества, используемую в соревновании: площадь под ROC кривой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "def auroc(y_prob, y_true):\n",
    "    m_minus = (y_true == 0).sum()\n",
    "    m_plus = (y_true == 1).sum()\n",
    "    \n",
    "    sorted_by_prob = sorted(zip(y_true, y_prob), key=lambda tup: tup[1], reverse=True)\n",
    "    sorted_y_true = zip(*sorted_by_prob)[0]\n",
    "    \n",
    "    fp, tp = 0, 0\n",
    "    fpr, tpr = [], []\n",
    "    f_prev = -inf\n",
    "    auc = 0\n",
    "    \n",
    "    for i in range(1, len(sorted_y_true)):\n",
    "        if y_prob[i] != f_prev:\n",
    "            fpr_i = fp / m_minus\n",
    "            fpr.append(fpr_i)\n",
    "            tpr_i = tp / m_plus\n",
    "            tpr.append(tpr_i)\n",
    "            f_prev = y_prob[i]\n",
    "        if y_true[i] == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "            auc += 1 / m_minus * tpr[-1]\n",
    "    return fpr, tpr, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку с помощью методики кросс-валидации для того, чтобы настроить параметр регуляризации $C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def cross_validation_score(model, X, Y):\n",
    "    kf = KFold(X1.shape[0], n_folds=10)\n",
    "    rocs = []\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        prob_pos = model.predict_proba(X_test)[:, 1]\n",
    "        #prob_pos[prob_pos > 0.5] = 1\n",
    "        #prob_pos[prob_pos <= 0.5] = 0\n",
    "        roc_auc = auroc(prob_pos, y_test)[2]\n",
    "        rocs.append(roc_auc)\n",
    "    return rocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with C=0.0\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "[0.60503072196620589, 0.5939975990396158, 0.55687074829931971, 0.63680084643870527, 0.54761904761904756, 0.60497596153846156, 0.58688020006733033, 0.56333808615966285, 0.57868333039957753, 0.57042850742447515]\n",
      "Accuracy: 0.584462504895\n",
      "Trying model with C=0.01\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "[0.60502272145417313, 0.59422969187675068, 0.55704681872749096, 0.63669664470414733, 0.54781105990783419, 0.60499198717948721, 0.58696035524775958, 0.56333808615966297, 0.57873133731257298, 0.57082853302611369]\n",
      "Accuracy: 0.58456572356\n",
      "Trying model with C=0.1\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "[0.60554275473630315, 0.59540616246498601, 0.55821528611444582, 0.63779477067602885, 0.54885112647209422, 0.60527243589743585, 0.58753747254685063, 0.56393886476874022, 0.57823526587828644, 0.5722046210957501]\n",
      "Accuracy: 0.585299876065\n",
      "Trying model with C=1\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "[0.60661482334869432, 0.6038735494197679, 0.56484993997599031, 0.6449766748424951, 0.55669162826420893, 0.60828525641025644, 0.59128873499094248, 0.56608564699851005, 0.58169976476612628, 0.58109318996415771]\n",
      "Accuracy: 0.590545920898\n",
      "Trying model with C=10\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "[0.615431387608807, 0.63563025210084034, 0.57867947178871559, 0.66235431795956978, 0.58554147465437789, 0.61851762820512823, 0.60756825213613563, 0.58592736186097183, 0.59341345153702141, 0.60704685099846389]\n",
      "Accuracy: 0.609011044885\n",
      "Trying model with C=100\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "[0.63324052739375314, 0.67249299719887945, 0.61874349739895962, 0.68758716875871695, 0.63530465949820791, 0.66160256410256402, 0.64179451417945144, 0.63307646710136345, 0.62954665471827953, 0.65244175627240153]\n",
      "Accuracy: 0.646583080662\n",
      "Trying model with C=1000\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "[0.67252304147465436, 0.68853141256502604, 0.65543017206882759, 0.721540903188573, 0.67231502816180244, 0.70668269230769243, 0.68100642844547044, 0.69563754625995289, 0.6857307452273127, 0.67273105478750628]\n",
      "Accuracy: 0.685212902449\n",
      "Trying model with C=10000\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "[0.67780337941628255, 0.68489795918367358, 0.67691076430572228, 0.73848570833132943, 0.68966013824884798, 0.72150641025641027, 0.69557864024751903, 0.71795446899181348, 0.71992766958442012, 0.667178699436764]\n",
      "Accuracy: 0.6989903838\n",
      "Best accuracy: 0.6989903838\n",
      "Best parameter: 10000\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masha/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "C = [0.0, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "def select_reg_parameter(C, X, Y):\n",
    "    best_accuracy = 0\n",
    "    best_c_ind = -1\n",
    "    best_c = -1\n",
    "    for c in C:\n",
    "        model = LogisticRegression(C=c)\n",
    "        print \"Trying model with C=\" + str(c)\n",
    "        score = cross_validation_score(model, X, Y)\n",
    "        print score\n",
    "        accuracy = numpy.mean(score)\n",
    "        print \"Accuracy: \" + str(accuracy)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_c_ind = C.index(c)\n",
    "            best_c = c\n",
    "    print \"Best accuracy: \" + str(best_accuracy)\n",
    "    print \"Best parameter: \" + str(best_c)\n",
    "    return best_c_ind\n",
    "\n",
    "index = select_reg_parameter(C, X1, Y)\n",
    "print index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем наилучшее значение $C$, и классифицируем неизвестных пользователей и строим ROC-кривую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier was fitted :)\n",
      "Data was predicted :)\n",
      "Area under the ROC curve : 0.704683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masha/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEPCAYAAABY9lNGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXkYvMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1130a1090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classify(X, Y, test_size, C):\n",
    "    \n",
    "    train_samples = int((1 - test_size)*Y.shape[0])\n",
    "\n",
    "    X_train = X1[:train_samples]\n",
    "    X_test = X1[train_samples:]\n",
    "    y_train = Y[:train_samples]\n",
    "    y_test = Y[train_samples:]\n",
    "    \n",
    "    lr = LogisticRegression(C=C)\n",
    "    lr.fit(X_train, y_train)\n",
    "    prob_pos = lr.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    roc_auc = auroc(prob_pos, y_test)[2]\n",
    "    tpr = auroc(prob_pos, y_test)[1]\n",
    "    fpr = auroc(prob_pos, y_test)[0]\n",
    "    \n",
    "    return tpr, fpr, roc_auc\n",
    "\n",
    "tpr, fpr, roc_auc = classify(X1, Y, 0.3, C[index])\n",
    "\n",
    "print \"Area under the ROC curve : %f\" % roc_auc\n",
    "\n",
    "def plot_roc_curve(tpr, fpr, roc_auc):\n",
    "    \"\"\"Plot ROC curve\"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    plt.fill_between(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc, alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "    pass\n",
    "\n",
    "plot_roc_curve(tpr, fpr, roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью полученной модели предсказываем категории для неизвестных пользователей из соревнования и загружаем на kaggle в нужном формате. ДЗ принимается только при наличии загруженных данных на kaggle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
